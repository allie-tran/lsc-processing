{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import json\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214189/4026103024.py:2: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv('VAISL/files/final_metadata.csv', sep=',', decimal='.')\n"
     ]
    }
   ],
   "source": [
    "unhelpful_images = json.load(open(\"files/unhelpful_images.json\"))\n",
    "metadata = pd.read_csv('VAISL/files/final_metadata.csv', sep=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['checkin'] = metadata['checkin'].fillna(\"\")\n",
    "metadata['city'] = metadata['city'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = [\"Province\", \"Área metropolitana de Madrid y Corredor del Henares\", \"Community of\", \"The Municipal District of\",\n",
    "                  \"Kreis\", \"Landkreis\", \"Regional Unit\", \"Municipal Unit\", \"Municipality\", \"Administrative District\", \"Region of\",\n",
    "                  \"Provence-Alpes-Côte d'Azur\", \"Municipal Borough District\", \"Subdistrict Administrative Organization\", \"Subdistrict\",\n",
    "                  \"District\", \"Distretto di\", \"Municipal District\", \"City\", \"Land \", \"Urban agglomeration\"]\n",
    "words_to_remove = sorted(words_to_remove, key=lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra(city):\n",
    "    city = city.split(\",\")\n",
    "    new_city = []\n",
    "    for name in city:\n",
    "        for word in words_to_remove:\n",
    "            name = name.replace(word, \"\")\n",
    "        name = name.replace(\"of \", \"\")\n",
    "        name = name.strip()\n",
    "        if name and name not in new_city:\n",
    "            new_city.append(name)\n",
    "    return \", \".join(new_city)\n",
    "        \n",
    "metadata[\"city\"] = metadata[\"city\"].apply(remove_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New timezone processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "country_geojson = geojson.load(open(\"files/countries.geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = set(metadata[\"country\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_data = {}\n",
    "for country in country_geojson[\"features\"]:\n",
    "    name = country[\"properties\"][\"ADMIN\"]\n",
    "    if name in all_countries or name in [\"United Kingdom\", \"South Korea\"]:\n",
    "        geojson_data[name] = country\n",
    "geojson_data[\"Korea\"] = geojson_data[\"South Korea\"]\n",
    "geojson_data[\"England\"] = geojson_data[\"United Kingdom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(geojson_data, open(\"files/backend/countries.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"new_timezone\"] = metadata[\"new_timezone\"].ffill()\n",
    "metadata[\"country\"] = metadata[\"country\"].fillna(\"\")\n",
    "metadata[\"OCR\"] = metadata[\"OCR\"].fillna(\"\")\n",
    "metadata[\"location_info\"] = metadata.apply(lambda row: row[\"categories\"] if row[\"stop\"] else row[\"checkin\"], axis=1)\n",
    "metadata[\"location_info\"] = metadata[\"location_info\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214189/2310336243.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(metadata.iterrows(), total=len(metadata)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3837d8b5ba90428fb6083d5d82775275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/723329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "info_dict = {}\n",
    "def to_full_key(image):\n",
    "    return f\"{image[:6]}/{image[6:8]}/{image}\"\n",
    "\n",
    "def to_local_time(utc_time, time_zone):\n",
    "    return utc_time.astimezone(tz.gettz(time_zone))\n",
    "\n",
    "# Calculate seconds from midnight from a datetime object\n",
    "def seconds_from_midnight(time):\n",
    "    return time.hour * 3600 + time.minute * 60 + time.second\n",
    "\n",
    "for index, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    image = row['ImageID']\n",
    "    if isinstance(image, str):\n",
    "        if image not in unhelpful_images:\n",
    "            image = to_full_key(image)\n",
    "            utc_time = datetime.strptime(row[\"minute_id\"]+\"00\", \"%Y%m%d_%H%M%S\").replace(tzinfo=tz.gettz('UTC'))\n",
    "            local_time = to_local_time(utc_time, row[\"new_timezone\"])\n",
    "            info_dict[image] = {\n",
    "                \"image_path\": image,\n",
    "                \"minute_id\": row[\"minute_id\"],\n",
    "                \"time\": datetime.strftime(local_time, \"%Y/%m/%d %H:%M:00%z\"),\n",
    "                \"utc_time\": datetime.strftime(utc_time, \"%Y/%m/%d %H:%M:00%z\"),\n",
    "                \"weekday\": datetime.strftime(local_time, \"%A\").lower(),\n",
    "                \"descriptions\": row['Tags'].lower().split(',') if isinstance(row['Tags'], str) else \"\",\n",
    "                \"address\": row[\"city\"],\n",
    "                \"location\": row[\"checkin\"] if row[\"stop\"] else \"None\",\n",
    "                \"location_info\": row[\"location_info\"],\n",
    "                \"gps\": {\"lat\": row[\"new_lat\"],\n",
    "                        \"lon\": row[\"new_lng\"]},\n",
    "                \"region\": row[\"city\"].lower().split(', '),\n",
    "                \"country\": row[\"country\"].lower(),\n",
    "                \"ocr\": row[\"OCR\"].split(', '),\n",
    "                \"timestamp\": utc_time.timestamp(),\n",
    "                \"seconds_from_midnight\": seconds_from_midnight(local_time)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "fields_to_fix = [\"address\", \"location\", \"region\"]\n",
    "for image in info_dict:\n",
    "    for field in fields_to_fix:\n",
    "        if isinstance(info_dict[image][field], str):\n",
    "            info_dict[image][field] = unidecode(\n",
    "                info_dict[image][field])\n",
    "        elif isinstance(info_dict[image][field], list):\n",
    "            info_dict[image][field] = [unidecode(s) for s in info_dict[image][field]]\n",
    "        elif np.isnan(info_dict[image][field]):\n",
    "            info_dict[image][field] = \"NONE\"\n",
    "        else:\n",
    "            print(field, info_dict[image][field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(info_dict, open(\"files/info_dict.json\", \"w\"))\n",
    "import json \n",
    "info_dict = json.load(open(f\"files/info_dict.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': '201901/06/20190106_171105_000.jpg',\n",
       " 'minute_id': '20190106_1711',\n",
       " 'time': '2019/01/06 19:11:00+0200',\n",
       " 'utc_time': '2019/01/06 17:11:00+0000',\n",
       " 'weekday': 'sunday',\n",
       " 'descriptions': ['table', 'food', 'plate', 'dish', 'meal'],\n",
       " 'address': 'Thessaloniki, Macedonia and Thrace, Greece',\n",
       " 'location': 'Eat Skaste',\n",
       " 'location_info': 'Souvlaki Shop',\n",
       " 'gps': {'lat': 40.6361591, 'lon': 22.9366191},\n",
       " 'region': ['thessaloniki', 'macedonia and thrace', 'greece'],\n",
       " 'country': 'greece',\n",
       " 'ocr': [''],\n",
       " 'timestamp': 1546794660.0,\n",
       " 'seconds_from_midnight': 69060,\n",
       " 'scene': 'S_1795',\n",
       " 'group': 'G_108'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dict[\"201901/06/20190106_171105_000.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713861 714583\n"
     ]
    }
   ],
   "source": [
    "groups = json.load(open('files/group_segments.json'))\n",
    "scene_info = {}\n",
    "\n",
    "assigned = []\n",
    "count = 0\n",
    "for group_name in groups:\n",
    "    group_id = int(group_name.split('_')[-1])\n",
    "    for scene_name, images in groups[group_name][\"scenes\"]:\n",
    "        images = [image for image in images if image in info_dict]\n",
    "        if not images:\n",
    "            continue\n",
    "        scene_info[scene_name] = {\n",
    "            \"group\": group_name,\n",
    "            \"images\": images,\n",
    "            \"start_time\": info_dict[images[0]][\"time\"],\n",
    "            \"end_time\": info_dict[images[-1]][\"time\"],\n",
    "            \"start_timestamp\": info_dict[images[0]][\"timestamp\"],\n",
    "            \"end_timestamp\": info_dict[images[-1]][\"timestamp\"],\n",
    "            \"start_seconds_from_midnight\": info_dict[images[0]][\"seconds_from_midnight\"],\n",
    "            \"end_seconds_from_midnight\": info_dict[images[-1]][\"seconds_from_midnight\"]\n",
    "        }\n",
    "        for key in [\"location\", \"location_info\", \"region\", \"country\", \"weekday\"]:\n",
    "            scene_info[scene_name][key] = info_dict[images[0]][key]\n",
    "        \n",
    "        for key in [\"gps\"]:\n",
    "            scene_info[scene_name][key] = [info_dict[image][key] for image in images]\n",
    "        \n",
    "        for image in images:\n",
    "            info_dict[image][\"scene\"] = scene_name\n",
    "            info_dict[image][\"group\"] = group_name\n",
    "            count += 1\n",
    "            assigned.append(image)\n",
    "\n",
    "print(len(set(assigned)), len(info_dict))\n",
    "# I THINK THERE'S SOMETHING WRONG HERE\n",
    "if len(set(assigned)) < len(info_dict):\n",
    "    to_remove = set(info_dict.keys()).difference(assigned)\n",
    "    for img in to_remove:\n",
    "        del info_dict[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(info_dict, open(\"files/info_dict.json\", \"w\"))\n",
    "json.dump(scene_info, open(f\"files/scene_dict.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718\n"
     ]
    }
   ],
   "source": [
    "locations = set([img[\"location\"].lower().strip() for img in info_dict.values()])\n",
    "if \"none\" in locations:\n",
    "    locations.remove(\"none\")\n",
    "extra = set()\n",
    "location_with_extras = {}\n",
    "for loc in locations:\n",
    "    if loc:\n",
    "        location_with_extras[loc] = []\n",
    "        for lengram in range(2, len(loc)):\n",
    "            for ngram in ngrams(loc.split(), lengram):\n",
    "                location_with_extras[loc].append(\" \".join(ngram))\n",
    "        location_with_extras[loc].append(loc)\n",
    "        location_with_extras[loc] = location_with_extras[loc][::-1]\n",
    "json.dump(location_with_extras, open(f'files/backend/locations.json', 'w'))\n",
    "print(len(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"home\" in locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = set([loc.lower().strip() for img in info_dict.values()\n",
    "               for loc in img[\"region\"]])\n",
    "json.dump(list(regions), open(f'files/backend/regions.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../UI/src/regions.js\", 'w') as f:\n",
    "    f.write(\"var regions=\" + json.dumps(list(regions)) + \";\\n\\nexport default regions;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(image):\n",
    "    return { key: info_dict[image][key] for key in [\"group\", \"scene\", \"time\", \"gps\", \"location\", \"location_info\"]}\n",
    "\n",
    "basic_dict = {image: filter_dict(image) for image in info_dict}\n",
    "json.dump(basic_dict, open(f'files/backend/basic_dict.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_info = {}\n",
    "def get_hour_minute(date_string):\n",
    "    datetime_value = datetime.strptime(date_string, \"%Y/%m/%d %H:%M:00%z\")\n",
    "    return datetime_value.strftime(\"%I:%M%p\")\n",
    "\n",
    "def get_final_time(first_info, last_info):\n",
    "    if first_info == last_info:\n",
    "        return first_info\n",
    "    return f\"{first_info} - {last_info}\"\n",
    "\n",
    "for group_name in groups:\n",
    "    group_first_info = None\n",
    "    group_last_info = None\n",
    "    for scene_name, images in groups[group_name][\"scenes\"]:\n",
    "        first_info = info_dict[images[0]][\"time\"]\n",
    "        last_info = info_dict[images[-1]][\"time\"]\n",
    "        if not group_first_info:\n",
    "            group_first_info = first_info\n",
    "        group_last_info = last_info\n",
    "        time_info[scene_name] = get_final_time(get_hour_minute(first_info), get_hour_minute(last_info))\n",
    "    time_info[group_name] = get_final_time(get_hour_minute(group_first_info), get_hour_minute(group_last_info))\n",
    "\n",
    "json.dump(time_info, open(f\"files/backend/time_info.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:05AM - 11:11AM'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_info[\"S_36\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duyen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
